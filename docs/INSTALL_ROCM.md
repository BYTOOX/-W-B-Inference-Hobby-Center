# Installation de ROCm sur Debian 13 (Trixie)

Ce guide d√©taille l'installation de ROCm 6.2+ pour AMD Ryzen AI MAX+ avec GPU Radeon 8060S (RDNA 3.5).

---

## üìã Pr√©requis

- **OS** : Debian 13 (Trixie) avec kernel 6.12+
- **GPU** : AMD Radeon (architecture RDNA 3.5)
- **Droits** : Acc√®s sudo

### V√©rifier votre GPU

```bash
lspci | grep -i amd
# Devrait afficher quelque chose comme : VGA compatible controller: AMD/ATI [Radeon ...]
```

---

## üöÄ Installation Automatique

Un script d'installation est fourni :

```bash
chmod +x install_rocm.sh
sudo ./install_rocm.sh
```

---

## üìñ Installation Manuelle

### 1. Mise √† jour du syst√®me

```bash
sudo apt update && sudo apt upgrade -y
```

### 2. Installation des d√©pendances

```bash
sudo apt install -y \
    wget \
    gnupg2 \
    software-properties-common \
    linux-headers-$(uname -r) \
    build-essential \
    dkms
```

### 3. Ajout du d√©p√¥t AMD ROCm

```bash
# T√©l√©charger et installer la cl√© GPG AMD
wget -qO - https://repo.radeon.com/rocm/rocm.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/rocm.gpg

# Ajouter le d√©p√¥t ROCm
echo "deb [arch=amd64 signed-by=/etc/apt/keyrings/rocm.gpg] https://repo.radeon.com/rocm/apt/6.2 jammy main" | \
    sudo tee /etc/apt/sources.list.d/rocm.list

# Pour Debian, on utilise le repo Ubuntu jammy qui est compatible
sudo apt update
```

> **Note** : ROCm n'a pas de d√©p√¥t officiel Debian 13, on utilise le d√©p√¥t Ubuntu 22.04 (jammy) qui est compatible.

### 4. Installation de ROCm

```bash
# Installation du meta-package ROCm
sudo apt install -y rocm-hip-runtime rocm-hip-sdk

# Ou installation compl√®te (plus lourd)
# sudo apt install -y rocm
```

### 5. Configuration de l'utilisateur

```bash
# Ajouter l'utilisateur aux groupes n√©cessaires
sudo usermod -aG video $USER
sudo usermod -aG render $USER

# Recharger les groupes (ou d√©connexion/reconnexion)
newgrp video
newgrp render
```

### 6. Variables d'environnement

Ajoutez √† votre `~/.bashrc` ou `~/.zshrc` :

```bash
# ROCm
export ROCM_PATH=/opt/rocm
export PATH=$ROCM_PATH/bin:$PATH
export LD_LIBRARY_PATH=$ROCM_PATH/lib:$LD_LIBRARY_PATH

# Pour PyTorch ROCm
export HSA_OVERRIDE_GFX_VERSION=11.0.0  # Ajuster selon votre GPU
```

Rechargez :

```bash
source ~/.bashrc
```

### 7. Red√©marrage

```bash
sudo reboot
```

---

## ‚úÖ V√©rification

### V√©rifier ROCm

```bash
# Liste des GPU d√©tect√©s
rocm-smi

# Version ROCm
rocminfo | head -20

# Test HIP
hipcc --version
```

Exemple de sortie `rocm-smi` :

```
========================= ROCm System Management Interface =========================
================================= Concise Info =====================================
GPU  Temp   AvgPwr  SCLK    MCLK    Fan   Perf  PwrCap  VRAM%  GPU%
0    45c    15W     500Mhz  1600Mhz 0%    auto  150W    5%     0%
====================================================================================
```

### V√©rifier avec Python

```bash
python3 -c "
import torch
print(f'PyTorch version: {torch.__version__}')
print(f'CUDA/ROCm available: {torch.cuda.is_available()}')
print(f'Device count: {torch.cuda.device_count()}')
if torch.cuda.is_available():
    print(f'Device name: {torch.cuda.get_device_name(0)}')
    print(f'Device memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')
"
```

---

## üêç Installation de PyTorch ROCm

### Via pip (recommand√©)

```bash
# Cr√©er un environnement virtuel
python3 -m venv venv
source venv/bin/activate

# Installer PyTorch pour ROCm 6.2
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.2

# Si ROCm 6.1
# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.1
```

### V√©rification

```bash
python -c "import torch; print(torch.cuda.is_available())"
# Doit afficher: True
```

---

## üîß D√©pannage

### GPU non d√©tect√©

```bash
# V√©rifier que le driver est charg√©
lsmod | grep amdgpu

# V√©rifier les permissions
ls -la /dev/dri/
# Vous devez avoir acc√®s √† renderD128

# Si probl√®me de permissions
sudo chmod 666 /dev/dri/renderD128
```

### Erreur HSA

Si vous avez des erreurs HSA, ajustez la version GFX :

```bash
# Pour RDNA 3.5 (gfx1150)
export HSA_OVERRIDE_GFX_VERSION=11.0.0

# Pour RDNA 3 (gfx1100)
export HSA_OVERRIDE_GFX_VERSION=11.0.0

# Pour RDNA 2 (gfx1030)
export HSA_OVERRIDE_GFX_VERSION=10.3.0
```

### PyTorch ne d√©tecte pas le GPU

```bash
# V√©rifier HIP
hipconfig --full

# Tester avec un calcul simple
python -c "
import torch
x = torch.randn(1000, 1000, device='cuda')
y = torch.matmul(x, x)
print('GPU computation OK!')
print(f'Result shape: {y.shape}')
"
```

---

## üìä Optimisations pour RyzenAI-LocalLab

### Unified Memory

Le Ryzen AI MAX+ utilise une m√©moire unifi√©e (shared entre CPU et GPU). Pour en tirer parti :

```python
# Dans le code d'inf√©rence
import torch

# Utiliser toute la m√©moire disponible
torch.cuda.set_per_process_memory_fraction(0.95)

# Pour les gros mod√®les, permettre le offload automatique
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    device_map="auto",  # Utilise GPU + CPU automatiquement
    torch_dtype=torch.float16,
    low_cpu_mem_usage=True
)
```

### Variables d'environnement recommand√©es

```bash
# Performance
export HIP_VISIBLE_DEVICES=0
export CUDA_VISIBLE_DEVICES=0

# M√©moire
export PYTORCH_HIP_ALLOC_CONF=expandable_segments:True

# Debug (si n√©cessaire)
export AMD_LOG_LEVEL=3
```

---

## üìö Ressources

- [Documentation ROCm officielle](https://rocm.docs.amd.com/)
- [PyTorch ROCm](https://pytorch.org/get-started/locally/)
- [ROCm GitHub](https://github.com/RadeonOpenCompute/ROCm)

---

## ‚ö†Ô∏è Notes Importantes

1. **Kernel 6.12+** : Requis pour le support RDNA 3.5
2. **Debian 13** : Utilise le d√©p√¥t Ubuntu jammy pour ROCm
3. **M√©moire partag√©e** : Le GPU utilise la RAM syst√®me, pas de VRAM d√©di√©e
4. **HSA_OVERRIDE_GFX_VERSION** : Peut √™tre n√©cessaire pour les GPU r√©cents
